# -*- coding: utf-8 -*-
"""model1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BQMy1NYWzc7GjRF1oYfj4i57d1nxudh8
"""

# import library
import os
import numpy as np
import matplotlib.pyplot as plt
import cv2 as cv
import tensorflow as tf
import pandas as pd
from tqdm.notebook import tqdm
from keras.models import Sequential, load_model, Model
from keras.layers import Dense
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Input, AveragePooling2D, GlobalAveragePooling2D
from sklearn.model_selection import train_test_split

# from google.colab import drive
# drive.mount('/content/drive')

# get path image from folder data and label for age and gender
path_data = '/content/drive/MyDrive/Model/UTKFace'
img_paths = []
age_labels = []
gender_labels = []

for img in tqdm(os.listdir(path_data)):
    img_path = os.path.join(path_data, img)
    image = img.split('_')
    ages = int(image[0])
    gender = int(image[1])
    img_paths.append(img_path)
    age_labels.append(ages)
    gender_labels.append(gender)

# create dataframe
df = pd.DataFrame()
df['image'], df['age'], df['gender'] =  img_paths, age_labels, gender_labels
   
y_gender = np.array(df['gender'])
y_age = np.array(df['age'])

# read image from paths
df = pd.DataFrame()
df['image'], df['age'], df['gender'] = img_paths, age_labels, gender_labels
def extract_features(images):
    features = []
    for image in tqdm(images):
        img = cv.imread(image, cv.IMREAD_GRAYSCALE)
        img = cv.resize(img, (128,128))
        img = np.array(img)
        features.append(img)
        
    features = np.array(features)
    # ignore this step if using RGB
    features = features.reshape(len(features), 128,128, 1)
    return features

X = extract_features(df['image'])
# normalize the images
X = X/255.0

# CNN netwworks to train model
input_shape =(128, 128, 1)
input = Input((input_shape))

# train gender
conv_1 = Conv2D(32, kernel_size=(3, 3),  activation='relu') (input)
maxp_1 = MaxPooling2D(pool_size=(2, 2)) (conv_1)
conv_2 = Conv2D(64, kernel_size=(3, 3),  activation='relu') (maxp_1)
maxp_2 = MaxPooling2D(pool_size=(2, 2)) (conv_2)
conv_3 = Conv2D(128, kernel_size=(3, 3),  activation='relu') (maxp_2)
maxp_3 = MaxPooling2D(pool_size=(2, 2)) (conv_3)
conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu') (maxp_3)
maxp_4 = MaxPooling2D(pool_size=(2, 2)) (conv_4)


flatten = Flatten() (maxp_4)

# fully connected layers
dense_1 = Dense(256, activation='relu') (flatten)
dropout_1 = Dropout(0.3) (dense_1)
output_1 = Dense(1, activation='sigmoid', name='gender_out') (dropout_1)

dense_2 = Dense(256, activation='relu') (flatten)
dropout_2 = Dropout(0.3) (dense_2)
output_2 = Dense(1, activation='relu', name='age_out') (dropout_2)

model = Model(inputs=[input], outputs=[output_1, output_2])


model.compile(loss=['binary_crossentropy', "mae"], optimizer='adam', metrics=['accuracy'])
model.summary()

# plot the model
from keras.utils import plot_model
plot_model(model)

history = model.fit(x=X, y=[y_gender, y_age], batch_size=32, epochs=30, validation_split=0.2)

model.save(f"/content/drive/MyDrive/Model/age_and_gender_3.h5", save_format='h5')

# map labels for gender
gender_dict = {0:'Male', 1:'Female'}

# Prediction with Test Data
image_index = 509
print("Original Gender:", gender_dict[y_gender[image_index]], "Original Age:", y_age[image_index])
# predict from model
pred = model.predict(X[image_index].reshape(1, 128, 128, 1))
pred_gender = gender_dict[round(pred[0][0][0])]
pred_age = round(pred[1][0][0])
print("Predicted Gender:", pred_gender, "Predicted Age:", pred_age)
plt.axis('off')
plt.imshow(X[image_index].reshape(128, 128), cmap='gray');